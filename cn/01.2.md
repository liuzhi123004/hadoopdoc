# 1.2 单机模式安装

**MapReduce安装包：**

* 你需要先从release版本中获得MapReduce的二进制包，如果没有你可以通过如下方式创建：
		$ mvn clean install -DskipTests
		$ cd hadoop-mapreduce-project
		$ mvn clean install assembly:assembly -Pnative
 
**设置环境变量：**

* 如果你已经安装好了hadoop-common/hadoop-hdfs 并且配置好环境变量： $HADOOP_COMMON_HOME/$HADOOP_HDFS_HOME。解压mapreduce的安装包并且设置环境变量：$HADOOP_MAPRED_HOME ，并且通同样设置YARN环境变量：$HADOOP_YARN_HOME 
* 注意：下面的介绍假定一已经运行起来hdfs

**配置文件设置：**
* 启动ResouceManager和NodeManager之前，你需要更改配置文件，假定你已经安装配置好HDFS（core-sitem.xml）,那么你还需要配置两个配置文件mapred-site.xml和yarn-site.xml
* 配置mapred-site.xml
	* 在mapred-site.xml添加如下内容：
			 <property>
			    <name>mapreduce.cluster.temp.dir</name>
			    <value></value>
			    <description>No description</description>
			    <final>true</final>
			  </property>

			  <property>
			    <name>mapreduce.cluster.local.dir</name>
			    <value></value>
			    <description>No description</description>
			    <final>true</final>
			  </property>
* 配置yarn-site.xml
	* 在yarn-site.xml中添加如下内容：
			<property>
			    <name>yarn.resourcemanager.resource-tracker.address</name>
			    <value>host:port</value>
			    <description>host is the hostname of the resource manager and 
			    port is the port on which the NodeManagers contact the Resource Manager.
			    </description>
			  </property>

			  <property>
			    <name>yarn.resourcemanager.scheduler.address</name>
			    <value>host:port</value>
			    <description>host is the hostname of the resourcemanager and port is the port
			    on which the Applications in the cluster talk to the Resource Manager.
			    </description>
			  </property>

			  <property>
			    <name>yarn.resourcemanager.scheduler.class</name>
			    <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler</value>
			    <description>In case you do not want to use the default scheduler</description>
			  </property>

			  <property>
			    <name>yarn.resourcemanager.address</name>
			    <value>host:port</value>
			    <description>the host is the hostname of the ResourceManager and the port is the port on
			    which the clients can talk to the Resource Manager. </description>
			  </property>

			  <property>
			    <name>yarn.nodemanager.local-dirs</name>
			    <value></value>
			    <description>the local directories used by the nodemanager</description>
			  </property>

			  <property>
			    <name>yarn.nodemanager.address</name>
			    <value>0.0.0.0:port</value>
			    <description>the nodemanagers bind to this port</description>
			  </property>  

			  <property>
			    <name>yarn.nodemanager.resource.memory-mb</name>
			    <value>10240</value>
			    <description>the amount of memory on the NodeManager in GB</description>
			  </property>
			 
			  <property>
			    <name>yarn.nodemanager.remote-app-log-dir</name>
			    <value>/app-logs</value>
			    <description>directory on hdfs where the application logs are moved to </description>
			  </property>

			   <property>
			    <name>yarn.nodemanager.log-dirs</name>
			    <value></value>
			    <description>the directories used by Nodemanagers as log directories</description>
			  </property>

			  <property>
			    <name>yarn.nodemanager.aux-services</name>
			    <value>mapreduce_shuffle</value>
			    <description>shuffle service that needs to be set for Map Reduce to run </description>
			  </property>

**设置capacity-scheduler.xml：**
* 确保下面内容添加到配置文件的跟节点下：
		 <property>
		    <name>yarn.scheduler.capacity.root.queues</name>
		    <value>unfunded,default</value>
		  </property>
		  
		  <property>
		    <name>yarn.scheduler.capacity.root.capacity</name>
		    <value>100</value>
		  </property>
		  
		  <property>
		    <name>yarn.scheduler.capacity.root.unfunded.capacity</name>
		    <value>50</value>
		  </property>
		  
		  <property>
		    <name>yarn.scheduler.capacity.root.default.capacity</name>
		    <value>50</value>
		  </property>

**启动程序**
* 确保以下环境变量都配置好：** $HADOOP_COMMON_HOME, $HADOOP_HDFS_HOME, $HADOO_MAPRED_HOME, $HADOOP_YARN_HOME, $JAVA_HOME ,$HADOOP_CONF_DIR**正确设置,**$YARN_CONF_DIR**和**$HADOOP_CONF_DIR**都正确配置
* 使用下面命令运行ResouceManager和NodeManager：
		$ cd $HADOOP_MAPRED_HOME
		$ sbin/yarn-daemon.sh start resourcemanager
		$ sbin/yarn-daemon.sh start nodemanager
* 运行测试例子
		$ $HADOOP_COMMON_HOME/bin/hadoop jar hadoop-examples.jar randomwriter out

**Good luck**

![](images/hadoop-logo.jpg?raw=true)

## links
  * 上一节: [概述](<01.1.md>)
  * 下一节: [集群模式安装](<01.3.md>)
